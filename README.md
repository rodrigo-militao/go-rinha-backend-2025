# Rinha de Backend 2025 - ImplementaÃ§Ã£o em Go

Esta Ã© a minha submissÃ£o para a 3Âª ediÃ§Ã£o da Rinha de Backend, desenvolvida em Go. O objetivo foi construir uma API de pagamentos resiliente e de alta performance, explorando padrÃµes de arquitetura de software e otimizaÃ§Ãµes avanÃ§adas.

## ğŸ›ï¸ Arquitetura

A arquitetura Ã© **assÃ­ncrona**, com duas instÃ¢ncias da API Go e uma instÃ¢ncia dedicada para o pool de workers. A comunicaÃ§Ã£o Ã© feita via Redis (fila) e o trÃ¡fego Ã© balanceado com NGINX.

```mermaid
graph TD
    subgraph Cliente
        A[Cliente k6]
    end

    subgraph AplicaÃ§Ã£o
        B(Nginx Load Balancer)
        C1[API Go - InstÃ¢ncia 1]
        C2[API Go - InstÃ¢ncia 2]
        D[Worker Go - Pool Dedicado]
    end

    subgraph Redis
        E[payments_queue - List]
        F["payments_hash - HSet (idempotÃªncia)"]
    end

    subgraph Processadores
        G[Default Processor]
        H[Fallback Processor]
    end

    A -->|HTTP POST /payments| B
    B --> C1
    B --> C2
    C1 -->|LPUSH| E
    C2 -->|LPUSH| E
    D -->|RPOPLPUSH/Processa/Salva| E
    D --> F
    D --> G
    D --> H
```

## âœ¨ Tecnologias Utilizadas

* **Linguagem:** Go 1.22+
* **Framework HTTP:** [fasthttp](https://github.com/valyala/fasthttp)
* **Cache / Banco de Dados de Estado:** Redis 7
* **Fila de Mensagens:** Redis (com listas)
* **Balanceador de Carga:** NGINX
* **Observabilidade:** [pprof](https://pkg.go.dev/net/http/pprof)
* **Testes de carga:** [k6](https://k6.io)
* **Ambiente:** Docker & Docker Compose


## âš™ï¸ EstratÃ©gias e OtimizaÃ§Ãµes

* **API desacoplada da lÃ³gica pesada:** apenas enfileira requisiÃ§Ãµes com latÃªncia <1ms.
* **Fila Redis (LPUSH + RPOPLPUSH):** sem bloqueio, com retry simples e reprocessamento.
* **Workers dedicados:** escalam de forma independente com `goroutines` e pooling de conexÃµes HTTP.
* **Health Check dinÃ¢mico:** verifica apenas o processador default. Usa `fallback` apenas se necessÃ¡rio.
* **HTTP ultra-performÃ¡tico:** uso de `fasthttp` e `HostClient` para latÃªncia mÃ­nima e alta reutilizaÃ§Ã£o de conexÃ£o.
* **IdempotÃªncia:** garantida via Redis `HSET` com chave `correlationId`.
* **Resumo de pagamentos:** calculado com agregaÃ§Ã£o em memÃ³ria via Redis Hashes (por segundo).
* **Observabilidade:** pprof ativado por padrÃ£o para profiling durante carga.

## ğŸ“Š Resultados da SubmissÃ£o

**ğŸ Total de pagamentos processados:** 16.749

* âœ… **p99:** `4.58ms`
* âœ… **Bonus de performance:** `+13%`
* âœ… **InconsistÃªncias:** `0`
* âœ… **Lag:** `0` (nenhuma perda de pagamentos)
* ğŸ’° **Lucro lÃ­quido final:** `R$ 350.029,26`
* ğŸ¦ **Pagamentos default:** 13.292 pagamentos
* âš ï¸ **Pagamentos fallback:** 3.457 pagamentos

> Esta pontuaÃ§Ã£o representa um dos melhores desempenhos jÃ¡ atingidos com Redis + Go no desafio.

## ğŸš€ Como Executar Localmente

```bash
./run-tests.sh # script que automatiza docker compose + testes k6
```

Ou manualmente:

```bash
docker compose down -v
docker compose up --build
k6 run rinha-test/rinha.js
```

## ğŸ—‚ï¸ Estrutura do Projeto

* `cmd/server/main.go` â†’ Ponto de entrada da aplicaÃ§Ã£o.
* `internal/domain` â†’ Entidades e interfaces.
* `internal/application` â†’ Casos de uso.
* `internal/infra/http` â†’ Rotas HTTP.
* `internal/infra/redis` â†’ ImplementaÃ§Ãµes com Redis.
* `internal/pprof` â†’ ExposiÃ§Ã£o do servidor pprof para profiling.

## ğŸ“ˆ Observabilidade (pprof)

Para utilizar o `pprof` na aplicaÃ§Ã£o, basta descomentar a linha 
```go
_ "rinha-golang/internal/pprof"
``` 
no arquivo `main.go`.

ApÃ³s isto, a aplicaÃ§Ã£o jÃ¡ inicia com o servidor `pprof` ativado na porta `:6060`. Para capturar CPU profile:

```bash
go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30
```

Para visualizar:

```bash
go tool pprof -http=:8081 profile.pb.gz
```

Ou, se preferir um relatÃ³rio em pdf apÃ³s a execuÃ§Ã£o, basta descomentar as linhas `21` a `25` no script `./run-tests.sh`.

## ğŸ‘¤ Autor

**Rodrigo MilitÃ£o**
ğŸ”— [LinkedIn](https://linkedin.com/in/rodrigo-militao)
